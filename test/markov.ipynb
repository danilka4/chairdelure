{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markovify\n",
    "\n",
    "This code is for training and testing the markov chain model for word recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 12:28:15.632914: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-27 12:28:20.817741: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: setuptools in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/chrisbonner/Documents/vt/chairdelure/.env/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import markovify\n",
    "import re\n",
    "import spacy\n",
    "import random\n",
    "\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the markov model based on our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"output\"\n",
    "\n",
    "with open(f\"../data/{file_name}_train.txt\") as f:\n",
    "    text = f.read()\n",
    "    \n",
    "with open(f\"../data/{file_name}_test.txt\") as f:\n",
    "    test_text = f.read().split(\"\\n\")\n",
    "\n",
    "training_model = markovify.NewlineText(text, state_size=3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the initial markov model for correct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test words: how do\n",
      "Model output: ['how', 'do', 'i', 'see', 'if', 'i', 'got', 'a', 'speaker', 'and', 'a', 'class', 'ring']\n",
      "Test words: more of\n",
      "Model output: ['more', 'of', 'a', 'secret', 'phase', 'within', 'one', 'of', 'the', 'profs', 'has', 'to', 'let', 'you', 'know', 'by', 'monday', 'if', 'that', 'works']\n",
      "Test words: i closed\n",
      "Model output: ['i', 'closed', 'my', 'eyes', 'for', 'a', 'second', 'lol', 'bout', 'to', 'say', '2506', 'is', 'just', 'a', 'slow', 'c', 'interpreter']\n",
      "Test words: bitch i\n",
      "Model output: ['bitch', 'i', 'just', 'want', 'to', 'be', 'my', 'new', 'bestie']\n",
      "Test words: me when\n",
      "Model output: ['me', 'when', 'i', 'miss', 'my', 'dual', 'monitor', 'setup']\n",
      "Test words: me with\n",
      "Model output: ['me', 'with', 'my', 'cs', 'homework', 'on', 'god', 'i', 'wanna', 'get', 'out']\n",
      "Test words: i thought\n",
      "Model output: ['i', 'thought', 'i', 'was', 'fruity']\n",
      "Test words: even if\n",
      "Model output: ['even', 'if', 'i', 'still', 'do', 'as', 'bad', 'as', 'homo', 'estas']\n",
      "Test words: dj be\n",
      "Model output: ['dj', 'be', 'like', 'icb', 'no', 'dj', ',', 'you', 'need', 'to', 'put', 'in', 'the', 'work', 'engineer', 'wouldve', 'been', 'on', 'his', 'diploma']\n",
      "Test words: i wouldn't\n",
      "Model output: ['i', \"wouldn't\", 'take', 'it', 'with', 'mano', '.']\n",
      "Test words: dj be\n",
      "Model output: ['dj', 'be', 'like', 'icb', 'no', 'dj', ',', 'you', 'need', 'to', 'be', 'like', 'to', 'be', 'like', 'them', 'fr', ':hundred_points:']\n",
      "Test words: i'm trying\n",
      "Model output: [\"i'm\", 'trying', 'to', 'read', 'up', ',', 'is', 'it', 'from', 'pbuffer', 'or', 'wordlist', '?']\n",
      "Test words: back in\n",
      "Model output: ['back', 'in', 'my', 'day', 'as', 'a', 'septuple-major', 'in', 'all', 'types', 'of', 'engineering', 'we', 'had', 'to', 'debate', 'whether', 'coincidences', 'exist', 'in', 'life', 'or', 'is', 'everything', 'predetermined']\n",
      "Test words: me with\n",
      "Model output: ['me', 'with', 'my', 'cs', 'homework', 'on', 'god', 'i', 'wanna', 'get', 'out']\n",
      "Test words: me with\n",
      "Model output: ['me', 'with', 'my', 'cs', 'homework', 'on', 'god', 'i', 'wanna', 'get', 'it', 'just', 'to', 'do', 'this']\n",
      "Test words: dj built\n",
      "Model output: ['dj', 'built', 'like', 'the', 'hamburgular']\n",
      "Test words: i bet\n",
      "Model output: ['i', 'bet', 'you', \"don't\", 'even', 'know', 'about', 'or', 'how', 'to', 'use', 'gdb', 'after', 'the', 'gdb', 'assignment', 'in', '2505']\n",
      "Test words: i was\n",
      "Model output: ['i', 'was', 'gonna', 'try', 'out', 'for', 'archery', 'in', 'middle', 'school', 'but', 'who', 'cares', 'about', 'what', 'i', 'think', \"he's\", 'gonna', 'get', 'to', 'those', 'lectures', 'in', 'class', 'before', 'the', 'assignment', 'is', 'due', 'lol']\n",
      "Test words: i thought\n",
      "Model output: ['i', 'thought', 'u', 'were', 'going', 'on', 'a', 'date', 'with', 'a', 'minor']\n",
      "Test words: i was\n",
      "Model output: ['i', 'was', 'gonna', 'go', 'to', 'the', 'agent', 'but', \"you're\", 'not', 'alone', 'and', 'you', 'can', 'still', 'go', 'to', 'them']\n",
      "Test words: i want\n",
      "Model output: ['i', 'want', 'to', 'kill', 'myself', 'in', 'front', 'of', 'you', 'to', 'see', 'where', 'the', 'symbol', 'was', 'used', 'but', \"that's\", 'ab', 'it']\n",
      "Test words: my brother\n",
      "Model output: ['my', 'brother', 'in', 'christ', '.', '.', '.', '.', '`', 'bc', 'this', 'is', 'the', 'exact', 'path']\n",
      "Test words: im trying\n",
      "Model output: ['im', 'trying', 'to', 'load', 'it', 'on', 'my', 'resume', 'too', 'lol']\n",
      "Test words: why did\n",
      "Model output: ['why', 'did', 'you', 'leave', 'to', 'get', 'the', 'journalism', 'of', 'the', 'decade', 'awards', 'are', 'given', 'by', 'the', 'cia', 'one', 'day']\n",
      "Test words: im trying\n",
      "Model output: ['im', 'trying', 'to', 'make', 'music']\n",
      "Test words: yeah .\n",
      "Model output: ['yeah', '.', '.', '.', '.']\n",
      "Test words: just wait\n",
      "Model output: ['just', 'wait', 'til', 'you', 'get', 'to', 'see', 'how', 'my', 'daily', 'use', 'is', 'to', 'upgrade']\n",
      "Test words: it's gonna\n",
      "Model output: [\"it's\", 'gonna', 'be', 'a', 'lot', 'of', 'work', 'and', 'stuff']\n",
      "Test words: i wish\n",
      "Model output: ['i', 'wish', 'i', 'was', 'a', 'purp', 'mod']\n",
      "Test words: yeah .\n",
      "Model output: ['yeah', '.', '.', '.', '.']\n",
      "Test words: ? ?\n",
      "Model output: ['?', '?', '?', '?', '?', '?', '?', '?', '?', '1984', 'joe', 'marx', 'orwell', 'biden']\n",
      "Test words: did u\n",
      "Model output: ['did', 'u', 'get', 'it', 'wrong', 'the', 'last', 'time', \"you've\", 'been', 'to', 'church']\n",
      "Test words: that is\n",
      "Model output: ['that', 'is', 'not', 'backed', 'up', 'by', 'facts', 'and', 'logic', 'at', 'this', 'point', 'is', 'to', 'cause', 'type', 'confusion', 'with', 'weak', 'vs', 'strong', 'symbols']\n",
      "Test words: i'm going\n",
      "Model output: [\"i'm\", 'going', 'to', 'bed', 'i', 'gotta', 'get', 'like', '40k', 'xp', 'in', '4', 'days']\n",
      "Test words: lemme take\n",
      "Model output: ['lemme', 'take', 'a', 'gander', 'at', 'this', 'meal', '.', '.', '.', 'something', 'bout', 'that', 'girl', \"isn't\", 'right', 'in', 'the', 'jim', 'crow', 'era']\n",
      "Test words: both of\n",
      "Model output: ['both', 'of', 'my', 'parents', 'are', 'using', 'it', 'rn']\n",
      "Test words: at least\n",
      "Model output: ['at', 'least', 'i', 'feel', 'like', \"i'm\", 'dying']\n",
      "Test words: i'm bout\n",
      "Model output: [\"i'm\", 'bout', 'to', 'get', 'a', 'job', 'again', 'next', 'semester']\n",
      "Test words: i got\n",
      "Model output: ['i', 'got', 'a', 'piano', 'lfggggg']\n",
      "Test words: it was\n",
      "Model output: ['it', 'was', 'the', 'worst', 'one']\n",
      "Test words: sorry to\n",
      "Model output: ['sorry', 'to', 'hear', 'i', 'hope', 'the', 'rapture', 'happens', 'soon']\n",
      "Test words: how else\n",
      "Model output: ['how', 'else', 'do', 'you', 'get', 'right', 'now', 'but', 'when', 'i', 'try', 'to', 'peel', 'it', 'says', 'the', 'stack', 'is', 'empty']\n",
      "Test words: i'm starting\n",
      "Model output: [\"i'm\", 'starting', 'to', 'seriously', 'think', 'i', 'have', 'it', 'on', 'my', 'resume', 'too', 'lol']\n",
      "Test words: yeah me\n",
      "Model output: ['yeah', 'me', 'and', 'qwyn', 'are', 'cinderellas', 'step', 'sisters']\n",
      "Test words: oh .\n",
      "Model output: ['oh', '.', '.', '.', '`']\n",
      "Test words: you should\n",
      "Model output: ['you', 'should', 'be', 'fine', 'to', 'take', 'a', 'parallelism', 'argument', 'which', 'is', 'what', 'it', 'should', 'be', 'blocked']\n",
      "Test words: there was\n",
      "Model output: ['there', 'was', 'a', 'shooting', 'in', 'blacksburg', 'that', 'town', 'is', 'so', 'small', 'and', 'it', 'was', 'one', 'key', 'too', 'far', 'to', 'be', 'comfortable', ':dotted_line_face:']\n",
      "Test words: but that\n",
      "Model output: ['but', 'that', 'was', 'also', 'before', 'i', 'was', 'a', 'turing', 'machine']\n",
      "Test words: it would\n",
      "Model output: ['it', 'would', 'be', 'a', 'trap']\n",
      "Test words: not really\n",
      "Model output: ['not', 'really', 'but', 'i', 'wanted', 'to', 'live', 'in', 'a', 'society']\n",
      "Test words: walli built\n",
      "Model output: ['walli', 'built', 'like', 'a', 'toucan']\n",
      "Test words: i have\n",
      "Model output: ['i', 'have', 'a', 'job', 'at', 'bb', 'last', 'summer']\n",
      "Test words: i'm in\n",
      "Model output: [\"i'm\", 'in', 'front', 'of', 'him']\n",
      "Test words: i feel\n",
      "Model output: ['i', 'feel', 'like', 'i', 'just', 'had', 'a', 'falling', 'out', 'with', 'a', 'bunch', 'of', 'cmda', 'kids']\n",
      "Test words: i had\n",
      "Model output: ['i', 'had', 'to', 'use', 'the', 'jus', 'compiler']\n",
      "Test words: i got\n",
      "Model output: ['i', 'got', 'a', 'job', 'at', 'a', 'big', 'company']\n",
      "Test words: consume consume\n",
      "Model output: ['consume', 'consume', 'consume', 'consume', 'consume']\n",
      "Test words: how do\n",
      "Model output: ['how', 'do', 'i', 'do', 'this']\n",
      "Test words: just gotta\n",
      "Model output: ['just', 'gotta', 'get', 'through', 'this', '&', 'next', 'semester']\n",
      "Test words: felt like\n",
      "Model output: ['felt', 'like', 'i', \"couldn't\", 'gotten', 'it', 'on', '4', 'but', 'i', 'was', 'just', 'copying', 'and', 'pasting', 'it', 'from', 'markdown']\n",
      "Test words: i tried\n",
      "Model output: ['i', 'tried', 'to', 'type', 'on', 'a', '60%', 'and', 'i', 'felt', 'like', 'i', \"couldn't\", 'gotten', 'it', 'on', '4', 'but', 'i', 'was', 'wondering', 'if', 'i', 'could', 'just', 'go', 'back', 'to', 'the', 'lot']\n",
      "Test words: just wait\n",
      "Model output: ['just', 'wait', 'til', 'my', 'pros', '1', 'and', 'get', 'the', \"xm4's\", 'instead']\n",
      "Test words: what if\n",
      "Model output: ['what', 'if', 'i', 'died', 'lol']\n",
      "Test words: i'm going\n",
      "Model output: [\"i'm\", 'going', 'to', 'go', 'to', 'sleep', 'when', 'i', 'was', 'playing', 'valorant', 'why', 'didnt', 'you', 'join', 'me', 'then', 'when', 'you', 'messaged']\n",
      "Test words: i'm taking\n",
      "Model output: [\"i'm\", 'taking', 'it', 'for', 'a', 'math', 'minor', 'is', 'even', 'if', \"it's\", 'just', 'counting']\n",
      "Test words: they need\n",
      "Model output: ['they', 'need', 'to', 'do', 'it', 'this', 'semester']\n",
      "Test words: i'm going\n",
      "Model output: [\"i'm\", 'going', 'to', 'kill', 'you', 'if', 'you', 'think', 'that', 'the', 'afternoon', 'discord', \"he's\", 'going', 'to', 'help', 'you', 'out']\n",
      "Test words: i feel\n",
      "Model output: ['i', 'feel', 'like', 'this', 'is', 'the', 'exact', 'same', 'thing', 'to', 'convince', 'others', 'their', 'actions', 'are', 'justified', 'and', 'correct']\n",
      "Test words: on the\n",
      "Model output: ['on', 'the', 'bright', 'side', 'i', 'have', 'a', 'responsibility', 'to', 'hold', 'dj', 'accountable', '.']\n",
      "Test words: a lot\n",
      "Model output: ['a', 'lot', 'of', 'not', 'even', 'you', \"don't\", 'have', 'to', 'endure', 'alone', 'anymore', '.', 'that', 'person', \"who's\", 'your', 'best', 'friend', 'by', 'your', 'side', 'til', 'the', 'day', 'you', 'just', 'need', 'to', 'remove', 'all', '@pids', 'from', 'athletes', ',', 'athletepositions', ',', 'and', 'playerstatsa']\n",
      "Test words: i'm going\n",
      "Model output: [\"i'm\", 'going', 'to', 'do', 'something']\n",
      "Test words: even if\n",
      "Model output: ['even', 'if', 'i', \"don't\", 'like', 'rating', 'other', 'people', 'unless', \"they're\", 'a', 'bad', 'person', 'if', 'he', 'did']\n",
      "Test words: you should\n",
      "Model output: ['you', 'should', 'go', 'to', 'a', 'dance', \"i'll\", 'be', 'back', 'like', 'jan', '14', 'if', 'you', 'need', 'any', 'help']\n",
      "Test words: boi what\n",
      "Model output: ['boi', 'what', 'the', 'hell', ':moai:']\n",
      "Test words: this might\n",
      "Model output: ['this', 'might', 'be', 'one', 'of', 'the', '1', 'credit', 'classes']\n",
      "Test words: im going\n",
      "Model output: ['im', 'going', 'to', 'bed', 'at', '1', 'wtf']\n",
      "Test words: have a\n",
      "Model output: ['have', 'a', 'good', 'night', 'qwynevere']\n",
      "Test words: more of\n",
      "Model output: ['more', 'of', 'a', 'secret', 'phase', 'within', 'one', 'of', 'the', 'reasons', \"i'm\", 'worried', 'about', 'going', 'straight', 'into', 'grad', 'school']\n",
      "Test words: me and\n",
      "Model output: ['me', 'and', 'my', 'friends', 'lives']\n",
      "Test words: you could\n",
      "Model output: ['you', 'could', 'try', 'to', 'reload', 'vsc', 'and', 'see', 'if', 'everything', 'makes', 'sense', '1', 'more', 'time', 'before', 'submitting']\n",
      "Test words: where are\n",
      "Model output: ['where', 'are', 'you', 'from', 'losertown', 'because', \"you're\", 'a', 'law', 'student', 'in', 'crippling', 'amounts', 'of', 'debt']\n",
      "Test words: but that\n",
      "Model output: ['but', 'that', 'was', 'also', 'before', 'i', 'was', 'medicated', 'so', 'i', 'was', 'like', '?', '?', '?', '?', '?']\n",
      "Test words: it would\n",
      "Model output: ['it', 'would', 'be', 'best', 'if', 'we', 'parted', 'ways', 'as', 'twitch', 'mod', '.', 'we', 'have', 'a', 'backup', 'plan', 'or', 'just', 'use', 'public', 'domain', 'pictures', '?']\n",
      "Test words: if it\n",
      "Model output: ['if', 'it', 'is', 'then', 'its', 'like', 'the', 'opposite', 'of', 'integers', 'just', 'take', 'the', 'pdf', 'not', 'the', 'latex', 'file']\n",
      "Test words: yeah i\n",
      "Model output: ['yeah', 'i', 'think', 'if', 'you', 'get', '3a', 'i', 'understand', 'it', 'now']\n",
      "Test words: walli built\n",
      "Model output: ['walli', 'built', 'like', 'a', 'typewriter']\n",
      "Test words: your ass\n",
      "Model output: ['your', 'ass', 'is', 'not', 'fuckin']\n",
      "Test words: oh yeah\n",
      "Model output: ['oh', 'yeah', 'i', 'hate', 'the', 'english', 'language']\n",
      "Test words: dj be\n",
      "Model output: ['dj', 'be', 'like', 'icb', 'no', 'dj', ',', 'you', 'need', 'to', 'worry', 'about', 'bc', 'your', 'program', 'does', 'the', 'math', 'for', 'you']\n",
      "Test words: i want\n",
      "Model output: ['i', 'want', 'to', 'get', 'into', 'omscs', 'but', 'idk', 'if', 'ill', 'be', 'on', 'in', 'a', 'little']\n",
      "Test words: on the\n",
      "Model output: ['on', 'the', 'bright', 'side', \"you're\", 'not', 'a', '30', 'year', 'old', 'admin', 'is', 'loving', 'all', 'this', 'juicy', 'drama', '!']\n",
      "Test words: why would\n",
      "Model output: ['why', 'would', 'they', 'want', 'to', 'spend', 'the', 'rest', 'of', 'your', 'weekend', 'goes', 'better']\n",
      "Test words: consume consume\n",
      "Model output: ['consume', 'consume', 'consume', 'consume', 'consume', 'consume']\n",
      "Test words: i use\n",
      "Model output: ['i', 'use', 'my', 'laptop', 'like', '80%', 'of', 'the', 'class', 'is', 'easy']\n",
      "Test words: you look\n",
      "Model output: ['you', 'look', 'like', 'one', 'of', 'the', '1', 'credit', 'classes']\n",
      "Test words: why would\n",
      "Model output: ['why', 'would', 'i', 'talk', 'to', 'them', 'or', 'give', 'them', 'any', 'attention']\n",
      "Test words: my brain\n",
      "Model output: ['my', 'brain', 'is', 'sizzling', 'trying', 'to', 'find', 'somewhere', 'to', 'rent', 'is', 'demotivating']\n",
      "Test words: i'll do\n",
      "Model output: [\"i'll\", 'do', 'it', 'once', 'i', 'did', 'electives']\n",
      "Test words: i used\n",
      "Model output: ['i', 'used', 'to', 'talk', 'to', 'an', 'advisor']\n",
      "Test words: they did\n",
      "Model output: ['they', 'did', 'it', 'to', 'me', 'back', 'when', 'i', 'did', 'my', 'initial', 'phone', 'call']\n",
      "Test words: hope you\n",
      "Model output: ['hope', 'you', 'all', 'are', 'having', 'a', 'mid', 'off']\n",
      "Test words: if you\n",
      "Model output: ['if', 'you', 'dont', 'want', 'any', 'overlap', 'i', 'was', 'just', 'trying', 'to', 'kill', 'everyone', 'then', 'if', \"it's\", 'not', 'occupation']\n",
      "Test words: i'm starting\n",
      "Model output: [\"i'm\", 'starting', 'to', 'burnout', 'early', \"that's\", 'the', 'one', 'of', 'the', 'dead', 'presidents', 'of', 'all', 'time']\n",
      "Test words: it might\n",
      "Model output: ['it', 'might', 'be', 'git', 'permissions', 'make', 'sure', \"you're\", 'using', 'the', 'right', 'account', 'if', 'you', 'have', 'any', 'other', 'pathways', 'you', 'need', 'i', 'would', 'do', 'capstone', 'in', 'spring']\n",
      "Test words: i'm bout\n",
      "Model output: [\"i'm\", 'bout', 'to', 'get', 'a', 'masters', 'while', 'working']\n",
      "Test words: im going\n",
      "Model output: ['im', 'going', 'to', 'kill', 'you', 'if', 'you', 'think', 'olive', 'garden', 'is', 'good']\n",
      "Test words: hope you\n",
      "Model output: ['hope', 'you', 'all', 'are', 'stupid']\n",
      "Test words: walli doesn't\n",
      "Model output: ['walli', \"doesn't\", 'talk', 'to', 'women', 'in', 'real', 'life']\n",
      "Test words: my brother\n",
      "Model output: ['my', 'brother', 'in', 'christ', '.', '.', '.', '.', '.', '.', 'mmm', 'looks', 'scrumptious', '!']\n",
      "Test words: a lot\n",
      "Model output: ['a', 'lot', 'of', 'time', 'on', 'discord', 'answering', 'questions', 'i', \"don't\", 'think', 'it', 'is']\n",
      "Test words: i'm trying\n",
      "Model output: [\"i'm\", 'trying', 'to', 'read', 'up', ',', 'is', 'it', 'from', 'pbuffer', 'or', 'wordlist', '?']\n",
      "Test words: i'm going\n",
      "Model output: [\"i'm\", 'going', 'to', 'kill', 'you', 'if', 'you', 'think', 'biscuits', 'are', 'd', 'tier']\n",
      "Test words: just wait\n",
      "Model output: ['just', 'wait', 'til', 'my', 'pros', '1', 'and', 'get', 'the', \"xm4's\", 'instead']\n",
      "Test words: i felt\n",
      "Model output: ['i', 'felt', 'like', 'a', 'systems', 'ta', 'has', 'to', 'have', 'the', 'last', 'name', 'miller']\n",
      "Correct: 0.0228\n",
      "Completed runs: 0.1534\n",
      "Invalid runs: 0.8238\n"
     ]
    }
   ],
   "source": [
    "correct = 0.0\n",
    "total_runs = 5000\n",
    "completed_runs = 0\n",
    "\n",
    "for i in range(total_runs):\n",
    "    rand = random.randint(0, len(test_text) - 180)\n",
    "    test_sentence = test_text[rand].split()\n",
    "    start_words = ' '.join(test_sentence[:2])\n",
    "    \n",
    "    try:\n",
    "        output = training_model.make_sentence_with_start(start_words, max_chars=180)\n",
    "        if output.split()[2] == test_sentence[2]:\n",
    "            correct += 1\n",
    "            # print(f'Test words: {start_words}\\nModel output: {output}')\n",
    "        completed_runs += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f'Correct: {correct / total_runs}')\n",
    "print(f'Completed runs: {(completed_runs - correct) / total_runs}')\n",
    "print(f'Invalid runs: {(total_runs - completed_runs) / total_runs}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll test spaCy's POS tagging with markovify to see if it improves text predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "class POSifiedText(markovify.Text):\n",
    "    def word_split(self, sentence):\n",
    "        return [\"::\".join((word.orth_, word.pos_)) for word in nlp(sentence)]\n",
    "\n",
    "    def word_join(self, words):\n",
    "        sentence = \" \".join(word.split(\"::\")[0] for word in words)\n",
    "        return sentence\n",
    "\n",
    "    def sentence_split(self, text):\n",
    "        return re.split(r\"\\s*\\n\\s*\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_model_2 \u001b[39m=\u001b[39m POSifiedText(text, state_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/vt/chairdelure/.env/lib/python3.10/site-packages/markovify/text.py:57\u001b[0m, in \u001b[0;36mText.__init__\u001b[0;34m(self, input_text, state_size, chain, parsed_sentences, retain_original, well_formed, reject_reg)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_size \u001b[39m=\u001b[39m state_size\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretain_original:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparsed_sentences \u001b[39m=\u001b[39m parsed_sentences \u001b[39mor\u001b[39;00m \u001b[39mlist\u001b[39;49m(\n\u001b[1;32m     58\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_corpus(input_text)\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     61\u001b[0m     \u001b[39m# Rejoined text lets us assess the novelty of generated sentences\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrejoined_text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentence_join(\n\u001b[1;32m     63\u001b[0m         \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_join, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparsed_sentences)\n\u001b[1;32m     64\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m, in \u001b[0;36mPOSifiedText.word_split\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mword_split\u001b[39m(\u001b[39mself\u001b[39m, sentence):\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39m::\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin((word\u001b[39m.\u001b[39morth_, word\u001b[39m.\u001b[39mpos_)) \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m nlp(sentence)]\n",
      "File \u001b[0;32m~/Documents/vt/chairdelure/.env/lib/python3.10/site-packages/spacy/language.py:1011\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[1;32m   1010\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/vt/chairdelure/.env/lib/python3.10/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/vt/chairdelure/.env/lib/python3.10/site-packages/spacy/pipeline/transition_parser.pyx:253\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/vt/chairdelure/.env/lib/python3.10/site-packages/spacy/pipeline/transition_parser.pyx:272\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/vt/chairdelure/.env/lib/python3.10/site-packages/thinc/model.py:849\u001b[0m, in \u001b[0;36mset_dropout_rate\u001b[0;34m(model, drop, attrs)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     node\u001b[39m.\u001b[39mattrs[attr] \u001b[39m=\u001b[39m value\n\u001b[1;32m    846\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m--> 849\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_dropout_rate\u001b[39m(model: _ModelT, drop: \u001b[39mfloat\u001b[39m, attrs\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mdropout_rate\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _ModelT:\n\u001b[1;32m    850\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Walk over the model's nodes, setting the dropout rate. You can specify\u001b[39;00m\n\u001b[1;32m    851\u001b[0m \u001b[39m    one or more attribute names, by default it looks for [\"dropout_rate\"].\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mwalk():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_model_2 = POSifiedText(text, state_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 0.0204\n",
      "Completed runs: 0.1606\n",
      "Invalid runs: 0.819\n"
     ]
    }
   ],
   "source": [
    "correct = 0.0\n",
    "completed_runs = 0\n",
    "\n",
    "for i in range(total_runs):\n",
    "    rand = random.randint(0, len(test_text) - 180)\n",
    "    test_sentence = test_text[rand].split()\n",
    "    start_words = ' '.join(test_sentence[:2])\n",
    "    \n",
    "    try:\n",
    "        output = training_model_2.make_sentence_with_start(start_words, max_chars=180)\n",
    "        if output.split()[2] == test_sentence[2]:\n",
    "            correct += 1\n",
    "            # print(f'Test words: {start_words}\\nModel output: {output}')\n",
    "        completed_runs += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f'Correct: {correct / total_runs}')\n",
    "print(f'Completed runs: {(completed_runs - correct) / total_runs}')\n",
    "print(f'Invalid runs: {(total_runs - completed_runs) / total_runs}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
